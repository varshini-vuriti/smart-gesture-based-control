This is the implementation of my 6th semester's mini project. I have also written a paper on the working of the project. You can find it in "paper.docx" file.
Abstract : This project aims to overcome these challenges by developing a lightweight and integrated system that combines multiple functionalities —such as mouse control, clicking, and typing—into a single, seamless interface. The proposed system leverages deep learning techniques to track hand movements and identify keypoints, enabling smooth and accurate gesture recognition. It is optimized for performance under varying lighting conditions and hand orientations while remaining efficient enough to run on resource constrained devices. Beyond basic controls, the project also explores additional features such as gesture-based typing to enhance usability and convenience. The expected outcome is a practical and responsive solution that simplifies human-computer interaction, offering a contactless alternative to traditional input devices. Its versatility makes it suitable for a wide range of applications, including assistive technologies, smart home systems, and virtual reality interfaces, providing an intuitive and accessible way to control devices through gestures.
